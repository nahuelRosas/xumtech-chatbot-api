import { Inject, Injectable } from '@nestjs/common';
import { MASTRA } from '../config/mastra.constants';
import { Mastra } from '@mastra/core/mastra';
import { QuestEngineService } from 'src/modules/quest-engine/application/service/quest-engine.service';
import {
  IResponse,
  RESPONSE_SERVICE,
} from 'src/common/response_service/interface/response.interface';
import { ResponseService } from 'src/common/response_service/service/response.service';
import { UnicodeNormalizer } from '@mastra/core/processors';
import { GEMINI_CLIENT } from '../config/model.config';
import { GoogleGenerativeAIProvider } from '@ai-sdk/google';
import { MastraLanguageModel } from '@mastra/core';
import { CreateChatDto } from '../dto/create-chat.dto';
import z from 'zod';
import { stepCountIs } from 'ai';

const outputSchema = z.object({
  text: z.string(),
});

@Injectable()
export class MastraService {
  private readonly mastra: Mastra;
  private readonly model: MastraLanguageModel;

  constructor(
    @Inject(MASTRA)
    mastraProvider: Mastra,
    private readonly questEngine: QuestEngineService,
    @Inject(RESPONSE_SERVICE)
    private readonly responseService: ResponseService,
    @Inject(GEMINI_CLIENT)
    geminiClient: GoogleGenerativeAIProvider,
  ) {
    this.responseService.setContext(MastraService.name);
    this.mastra = mastraProvider;
    this.model = geminiClient('gemini-2.5-flash-lite');
  }

  public async chatWithAgent(
    dto: CreateChatDto,
    resourceId: string,
  ): Promise<
    IResponse<{
      answer: string;
    }>
  > {
    try {
      const { message, conversationId } = dto;
      const allowedQuestions = (await this.questEngine.getAllQuests()).payload;
      const assistantPrompt = `Allowed questions and answers:\n${allowedQuestions
        .map(
          (s) =>
            `- Q: ${s.question ?? JSON.stringify(s)}\n  A: ${s.answer ?? ''}`,
        )
        .join('\n')}`;

      const response = await this.mastra
        .getAgent('questAgent')
        .generateVNext<
          typeof outputSchema
        >([{ role: 'user', content: message }], {
          context: [{ role: 'assistant', content: assistantPrompt }],
          resourceId: resourceId || 'anon',
          threadId: conversationId,
          output: outputSchema,
          stopWhen: stepCountIs(15),
          modelSettings: {
            temperature: 0.5,
            maxOutputTokens: 10000,
            topP: 0.8,
          },
          inputProcessors: [
            new UnicodeNormalizer({
              stripControlChars: true,
              collapseWhitespace: true,
              preserveEmojis: true,
              trim: true,
            }),
          ],
          providerOptions: {
            google: {
              safetySettings: [
                {
                  category: 'HARM_CATEGORY_HATE_SPEECH',
                  threshold: 'BLOCK_LOW_AND_ABOVE',
                },
                {
                  category: 'HARM_CATEGORY_DANGEROUS_CONTENT',
                  threshold: 'BLOCK_LOW_AND_ABOVE',
                },
                {
                  category: 'HARM_CATEGORY_HARASSMENT',
                  threshold: 'BLOCK_LOW_AND_ABOVE',
                },
                {
                  category: 'HARM_CATEGORY_SEXUALLY_EXPLICIT',
                  threshold: 'BLOCK_LOW_AND_ABOVE',
                },
              ],
              thinkingConfig: {
                thinkingBudget: 1000,
                includeThoughts: false,
              },
            },
          },
        });

      return this.responseService.createResponse({
        message: 'Answer generated by agent (fallback)',
        type: 'OK',
        payload: {
          answer: outputSchema.parse(response.object).text,
        },
      });
    } catch (error) {
      this.responseService.errorHandler({ error });
    }
  }
}
